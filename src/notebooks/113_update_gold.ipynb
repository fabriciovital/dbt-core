{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c2b44f8-81cf-4677-a3bf-67fb009b1947",
   "metadata": {},
   "source": [
    "# update_gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb9343f-751f-4465-88f1-d7d550fb980c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd26d97-60c1-4c0c-9bec-2349c8a84c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "from configs import configs\n",
    "from functions import functions as F\n",
    "from pyspark.sql import functions as func\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d918d03-8a40-4546-9a5f-6af6094230ff",
   "metadata": {},
   "source": [
    "## Import Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd55f32-e80f-4b20-be1d-ed2d90467253",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "HOST_ADDRESS_MINIO=os.getenv('HOST_ADDRESS_MINIO')\n",
    "MINIO_ACCESS_KEY=os.getenv('MINIO_ACCESS_KEY')\n",
    "MINIO_SECRET_KEY=os.getenv('MINIO_SECRET_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab74f57-3291-47c0-bea6-c2b1bcef5cea",
   "metadata": {},
   "source": [
    "## Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3f7bf8-e1eb-40a5-9ef1-6ace462fe088",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_spark():\n",
    "    \"\"\"Configure and return a SparkSession.\"\"\"\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"update_gold\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.endpoint\", f\"http://{HOST_ADDRESS_MINIO}:9000\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.access.key\", MINIO_ACCESS_KEY) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.secret.key\", MINIO_SECRET_KEY) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.path.style.access\", True) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\") \\\n",
    "        .config(\"hive.metastore.uris\", \"thrift://metastore:9083\") \\\n",
    "        .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "        .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "        .getOrCreate()\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1e68e9-e58a-4858-80bf-1b60908a5bb2",
   "metadata": {},
   "source": [
    "## Function Ingest Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a0e9b8-7c0c-4373-903f-783908eccbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_data(): \n",
    "    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')  \n",
    "    logging.info(\"Starting ingestion...\")\n",
    "    \n",
    "    input_prefix_layer = configs.prefix_layer_name['2']\n",
    "    storage_input = configs.lake_path['silver']\n",
    "    \n",
    "    output_prefix_layer = configs.prefix_layer_name['3']\n",
    "    storage_output = configs.lake_path['gold']\n",
    "    \n",
    "    for table_name, query in configs.tables_gold.items():\n",
    "        \n",
    "        input_path = f'{storage_input}{input_prefix_layer}{table_name}'\n",
    "        output_path = f'{storage_output}{output_prefix_layer}{table_name}'\n",
    "        \n",
    "        try:\n",
    "            max_modified_date_destination = spark.read.format(\"delta\") \\\n",
    "                .load(output_path) \\\n",
    "                .select(func.max(\"modifieddate\") \\\n",
    "                .alias(\"max_modifieddate\")) \\\n",
    "                .collect()[0][\"max_modifieddate\"]\n",
    "            #print(max_modified_date_destination)\n",
    "            \n",
    "            query_input_data = f\"\"\"\n",
    "            select * from ({query}) as subquery\n",
    "            where modifieddate > '{max_modified_date_destination}'\n",
    "            \"\"\"\n",
    "            \n",
    "            df_input_data = spark.sql(query_input_data)\n",
    "                  \n",
    "            input_data_count = df_input_data.count()\n",
    "            logging.info(f\"Number os rows processed for table {table_name}: {input_data_count}\")\n",
    "            \n",
    "            if input_data_count == 0:\n",
    "                logging.info(f\"No new data to process for table {table_name}.\")\n",
    "                continue\n",
    "                      \n",
    "            df_with_update_date = F.add_metadata(df_input_data)\n",
    "            df_with_month_key = F.add_month_key(df_with_update_date, 'modifieddate')\n",
    "            \n",
    "            df_with_month_key.write.format(\"delta\").mode(\"append\").partitionBy(\"month_key\").save(output_path)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing table {table_name}: {str(e)}.\")\n",
    "    \n",
    "    logging.info(\"Ingestion completed!\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b975f7-dcd0-45a7-8407-21cf6ea8ff9b",
   "metadata": {},
   "source": [
    "## Function Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5c73ef-2951-4223-bbc6-2bdff16d647b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    spark = configure_spark()\n",
    "    ingest_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d3f2e7-d553-4fed-ba43-4e33007ef2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"delta\").load('s3a://gold/adventure_works/gold_humanresources_department').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b0f865-cbff-4ad8-9c05-d788e0d25a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"delta\").load('s3a://gold/adventure_works/gold_humanresources_groupname_qtd').show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
